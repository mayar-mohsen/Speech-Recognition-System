{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <span style=\"color:GREEN\"> COMMANDS SYSTEM USING CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esraa\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\Esraa\\Anaconda3\\lib\\site-packages\\malaya_boilerplate\\frozen_graph.py:35: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  'Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                        # linear algebra library\n",
    "import pandas as pd                       # data frames processing\n",
    "import matplotlib.pyplot as plt           # visualization library\n",
    "import seaborn as sn                      # visualization library\n",
    "import math\n",
    "import keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Audio processing libraries\n",
    "import scipy.io.wavfile as wav\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal as signal\n",
    "import noisereduce as nr\n",
    "from IPython.display import Audio, IFrame, display\n",
    "from scipy.signal import hilbert\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "import soundfile as sf\n",
    "import malaya_speech\n",
    "import webrtcvad\n",
    "from webrtcvad import Vad\n",
    "from malaya_speech import Pipeline\n",
    "import speech_recognition as spreg\n",
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "#simulation library\n",
    "import pygame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('commands_CNN.h5')    #loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"down\",\"left\",\"right\",\"stop\",\"up\"]    #output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr=16000                                        # sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_preprocessing(wave):\n",
    "    \"\"\" this function takes file.wav and process it through the following steps:\n",
    "        1. reduce bakground noise.\n",
    "        2. silence removal\"spectral gating\".   ################\n",
    "        3. padding with zeros to have a constant vector length.\n",
    "     Input: audio_file.wav\n",
    "     Output: sampled signal\"\"\"\n",
    "    samples = nr.reduce_noise(y=wave, sr=sr,stationary=True)\n",
    "    vad = malaya_speech.vad.webrtc()\n",
    "    y_= malaya_speech.resample(samples, sr, 16000)\n",
    "    y_ = malaya_speech.astype.float_to_int(y_)\n",
    "    frames = malaya_speech.generator.frames(samples, 30, sr)\n",
    "    frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\n",
    "    frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n",
    "    y_ = malaya_speech.combine.without_silent(frames_webrtc)\n",
    "    if len(y_)>=19999:\n",
    "            y_=y_[:19999]\n",
    "    size = (1*sr+4000)-y_.shape[0]\n",
    "    zero = np.zeros(size)\n",
    "    signal = np.concatenate((y_,zero))\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCCs(signal):\n",
    "    \"\"\"this function extract MFCCs from samples signal\"\"\"\n",
    "    mfcc_feat = mfcc(signal, sr, winlen=256/sr, winstep=256/(2*sr), numcep=13, nfilt=26, nfft=256,\n",
    "                 lowfreq=0, highfreq=sr/2, preemph=0.97, ceplifter=22, appendEnergy=True, winfunc=np.hamming)\n",
    "    audio = np.transpose(mfcc_feat)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 1200          # silence threshold\n",
    "CHUNK_SIZE = 1024         # frame size\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 16000              # sample rate\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.128 second of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 2:\n",
    "            break\n",
    "        \n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data as output file\"\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(sound_file):\n",
    "    \"\"\"this function plays audio in jupyter notebook\"\"\"\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    sd.play(wave, sr)\n",
    "    status = sd.wait()  # Wait until file is done playing\n",
    "#play_audio(wave,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(sound_file):\n",
    "    \"\"\"this function plots audio wave in jupyter notebook \"\"\"\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    samples = wave\n",
    "    time = np.linspace(0, len(samples - 1) / sr, len(samples - 1))\n",
    "    plt.plot(time,samples)  \n",
    "    plt.title(\"Voice Signal\")\n",
    "    plt.xlabel(\"Time [seconds]\")\n",
    "    plt.ylabel(\"Voice amplitude\")\n",
    "    plt.show()\n",
    "#plot_audio(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_func(sound_file):\n",
    "    \"\"\"this function takes sound file and call processing function to \n",
    "    adjust it then pass it to the MFCC function to be converted  then \n",
    "    passed to the model for prediction.\"\"\"\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    fs = sr\n",
    "    signal=audio_preprocessing(wave)\n",
    "    audio=MFCCs(signal)\n",
    "    d1 = np.array(audio.shape[0])\n",
    "    d2 = np.array(audio.shape[1])\n",
    "    d = d1*d2\n",
    "    r = []\n",
    "    r = model.predict(audio.reshape(1,d1,d2,-1))\n",
    "    ind = np.argmax(r)\n",
    "    output=classes[ind]\n",
    "    print('**** predicted output is: ',classes[ind], '****')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_func():\n",
    "    \"\"\"this fuction runs in the background continously to detect audio\"\"\"\n",
    "    while True:\n",
    "        global o_p\n",
    "        print(\"please speak a word into the microphone\")\n",
    "        record_to_file('demo.wav')\n",
    "        sound_file=\"demo.wav\"\n",
    "        o_p=pred_func(sound_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please speak a word into the microphone\n"
     ]
    }
   ],
   "source": [
    "game=threading.Thread(target=run_func)      # intialize thread to run in the background\n",
    "game.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaion of the Game Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate the pygame library .\n",
    "# initiate pygame and give permission\n",
    "# to use pygame's functionality.\n",
    "pygame.init()\n",
    "\n",
    "# create the display surface object of specific dimension..e(500, 500).\n",
    "win = pygame.display.set_mode((500, 500))\n",
    "\n",
    "# set the pygame window name\n",
    "pygame.display.set_caption(\"Moving rectangle\")\n",
    "\n",
    "# object current co-ordinates\n",
    "x = 200\n",
    "y = 200\n",
    "\n",
    "# dimensions of the object\n",
    "width = 20\n",
    "height = 20\n",
    "\n",
    "# velocity / speed of movement\n",
    "vel = 0.02\n",
    "i=0\n",
    "o_p=''\n",
    "# Indicates pygame is running\n",
    "run = True\n",
    "# infinite loop\n",
    "while run:\n",
    "    # iterate over the list of Event objects that was returned by pygame.event.get() method.\n",
    "    for event in pygame.event.get():\n",
    "\n",
    "        # if event object type is QUIT then quitting the pygame and program both.\n",
    "        if event.type == pygame.QUIT:\n",
    "\n",
    "            # it will make exit the while loop\n",
    "            run = False\n",
    "        \n",
    "    # if left word is detected\n",
    "    if o_p =='left' and x>0:\n",
    "        x -= vel          # decrement in x co-ordinate\n",
    "\n",
    "\n",
    "    # if right word is detected\n",
    "    if o_p =='right' and x<500-width:\n",
    "        x += vel          # increment in x co-ordinate\n",
    "\n",
    "\n",
    "    # if up word is detected\n",
    "    if o_p =='up' and y>0:\n",
    "        y -= vel         # decrement in y co-ordinate\n",
    "\n",
    "\n",
    "    # if down word is detected\n",
    "    if o_p =='down' and y<500-height:\n",
    "        y += vel            # increment in y co-ordinate\n",
    "   \n",
    "    # if stop word is detected\n",
    "    if o_p =='stop' :\n",
    "        y = y            # freeze in same position\n",
    "        x = x\n",
    "       \n",
    "    # completely fill the surface object with black colour\n",
    "    win.fill((0, 0, 0))\n",
    "\n",
    "    # drawing object on screen which is rectangle \n",
    "    pygame.draw.rect(win, (255, 0, 0), (x, y, width, height))\n",
    "\n",
    "    # it refreshes the window\n",
    "    pygame.display.update()\n",
    "    \n",
    "# closes the pygame window\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
