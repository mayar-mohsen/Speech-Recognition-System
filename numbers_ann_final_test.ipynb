{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <span style=\"color:GREEN\"> NUMBER SYSTEM USING ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np                        # linear algebra library\n",
    "import pandas as pd                       # data frames processing\n",
    "import matplotlib.pyplot as plt           # visualization library\n",
    "import seaborn as sn                      # visualization library\n",
    "import math\n",
    "import keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Audio processing libraries\n",
    "import scipy.io.wavfile as wav\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal as signal\n",
    "import noisereduce as nr\n",
    "from IPython.display import Audio, IFrame, display\n",
    "from scipy.signal import hilbert\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "import soundfile as sf\n",
    "import malaya_speech\n",
    "import webrtcvad\n",
    "from webrtcvad import Vad\n",
    "from malaya_speech import Pipeline\n",
    "import speech_recognition as spreg\n",
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "#simulation library\n",
    "import pygame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('numbers_ANN.h5')   #loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"eight\",\"five\",\"four\",\"nine\",\"one\",\"seven\",\"six\",\"three\",\"two\",\"zero\"]   # output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr=16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_preprocessing(wave):\n",
    "    \"\"\" this function takes file.wav and process it through the following steps:\n",
    "        1. reduce bakground noise.\n",
    "        2. silence removal\"spectral gating\".   ################\n",
    "        3. padding with zeros to have a constant vector length.\n",
    "     Input: audio_file.wav\n",
    "     Output: sampled signal\"\"\"\n",
    "    samples = nr.reduce_noise(y=wave, sr=sr,stationary=True)\n",
    "    vad = malaya_speech.vad.webrtc()\n",
    "    y_= malaya_speech.resample(samples, sr, 16000)\n",
    "    y_ = malaya_speech.astype.float_to_int(y_)\n",
    "    frames = malaya_speech.generator.frames(samples, 30, sr)\n",
    "    frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\n",
    "    frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n",
    "    y_ = malaya_speech.combine.without_silent(frames_webrtc)\n",
    "    if len(y_)>=19999:\n",
    "            y_=y_[:19999]\n",
    "    size = (1*sr+4000)-y_.shape[0]\n",
    "    zero = np.zeros(size)\n",
    "    signal = np.concatenate((y_,zero))\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCCs(signal):\n",
    "    \"\"\"this function extract MFCCs from samples signal\"\"\"\n",
    "    mfcc_feat = mfcc(signal, sr, winlen=256/sr, winstep=256/(2*sr), numcep=13, nfilt=26, nfft=256,\n",
    "                 lowfreq=0, highfreq=sr/2, preemph=0.97, ceplifter=22, appendEnergy=True, winfunc=np.hamming)\n",
    "    audio = np.transpose(mfcc_feat)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 1200          # silence threshold\n",
    "CHUNK_SIZE = 1024         # frame size\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 16000              # sample rate\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.128 seconds of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 2:\n",
    "            break\n",
    "        \n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    r = normalize(r)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data as output file\"\n",
    "    \n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(sound_file):\n",
    "    \"\"\"this function plots audio wave in jupyter notebook \"\"\"\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    sd.play(wave, sr)\n",
    "    status = sd.wait()  # Wait until file is done playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(sound_file):\n",
    "    \"\"\"this function plots audio wave in jupyter notebook \"\"\"\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    samples = wave\n",
    "    time = np.linspace(0, len(samples - 1) / sr, len(samples - 1))\n",
    "    plt.plot(time,samples)  \n",
    "    plt.title(\"Voice Signal\")\n",
    "    plt.xlabel(\"Time [seconds]\")\n",
    "    plt.ylabel(\"Voice amplitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_func(sound_file):\n",
    "    \"\"\"this function takes sound file and call processing function to \n",
    "    adjust it then pass it to the MFCC function to be converted  then \n",
    "    passed to the model for prediction.\"\"\"\n",
    "    global flag\n",
    "    wave, sr = sf.read(sound_file, dtype='float32')  \n",
    "    fs = sr\n",
    "    signal=audio_preprocessing(wave)\n",
    "    audio=MFCCs(signal)\n",
    "    d1 = np.array(audio.shape[0])\n",
    "    d2 = np.array(audio.shape[1])\n",
    "    d = d1*d2\n",
    "    r = []\n",
    "    r = model.predict(audio.reshape(1,d))\n",
    "    ind = np.argmax(r)\n",
    "    output=classes[ind]\n",
    "    print('**** predicted output is: ',classes[ind], '****')\n",
    "    flag = 1\n",
    "    return output,flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_func():\n",
    "    \"\"\"this fuction runs in the background continously to detect audio\"\"\"\n",
    "    while True:\n",
    "        global o_p\n",
    "        global flag\n",
    "        print(\"speak now\")\n",
    "        record_to_file('demo.wav')\n",
    "        sound_file=\"demo.wav\"\n",
    "        o_p,flag=pred_func(sound_file)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game=threading.Thread(target=run_func)   # intialize thread to run in the background\n",
    "game.start()    #speak zeo here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Numbers simulation inside notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "temp=''\n",
    "text_t=['0','1','2','3','4','5','6','7','8','9']  #output classes\n",
    "#flag=0\n",
    "# infinite loop\n",
    "while True:\n",
    "    if flag == 1:\n",
    "        if o_p == 'zero' :\n",
    "            u=0\n",
    "        elif o_p == 'one':\n",
    "            u=1\n",
    "        elif o_p == 'two':\n",
    "            u=2\n",
    "        elif o_p == 'three':\n",
    "            u=3\n",
    "        elif o_p == 'four':\n",
    "            u=4\n",
    "        elif o_p == 'five':\n",
    "            u=5\n",
    "        elif o_p == 'six':\n",
    "            u=6\n",
    "        elif o_p == 'seven':\n",
    "            u=7\n",
    "        elif o_p == 'eight':\n",
    "            u=8\n",
    "        elif o_p == 'nine':\n",
    "            u=9\n",
    "        flag = 0   \n",
    "    \n",
    "        temp=temp+text_t[u]\n",
    "        clear_output()\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,2))\n",
    "        ax = fig.add_subplot()\n",
    "        fig.subplots_adjust(top=0.85)\n",
    "        ax.axis([0, 10, 0, 10])\n",
    "        ax.text(0,1 , temp , fontsize=100)\n",
    "        plt.title(str(temp))\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
